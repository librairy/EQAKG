{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tj766chAT3aY",
   "metadata": {
    "id": "tj766chAT3aY"
   },
   "source": [
    "# Approach\n",
    "\n",
    "Use of official APIs from Wikidata and DBpedia to retrieve candidates from the entities discovered. Then, apply a ranking algorithm to select the resource as the best candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nR-jBsPFx9VX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nR-jBsPFx9VX",
    "outputId": "ebe28f9d-5203-4ffe-bca7-8586453955d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/cbadenes/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/cbadenes/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON  \n",
    "import pandas as pd\n",
    "import urllib.request as url\n",
    "import json\n",
    "import requests\n",
    "\n",
    "sentence_language_model = \"sentence-transformers/all-distilroberta-v1\"\n",
    "sentence_model = SentenceTransformer(sentence_language_model)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "wiki_cache = {}\n",
    "dbpedia_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vy9nB1vksdQ-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vy9nB1vksdQ-",
    "outputId": "ab66a3e6-cfde-4720-a022-c43f662378bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma: Turing award\n"
     ]
    }
   ],
   "source": [
    "def lemmatize(text):\n",
    "  result = []\n",
    "  for token in text.split(\" \"):\n",
    "    result.append(lemmatizer.lemmatize(token))\n",
    "  return \" \".join(result)\n",
    "\n",
    "print(\"Lemma:\",lemmatize(\"Turing awards\"))\n",
    "\n",
    "def sort_by_similar(text,texts):\n",
    "  sentences = [text]\n",
    "  sentences.extend(texts)\n",
    "  embeddings = sentence_model.encode(sentences)\n",
    "  sim_list = []\n",
    "  index=0\n",
    "  for e in embeddings[1:]:\n",
    "    ref = embeddings[0]\n",
    "    score = cosine_similarity([ref], [e])\n",
    "    score_val = round(score[0][0], 1)\n",
    "    sim_list.append({'id':index, 'text':texts[index], 'score':score_val})  \n",
    "    index+=1\n",
    "  sim_list.sort(key=lambda x: x.get('score'),reverse=True)\n",
    "  return sim_list\n",
    "\n",
    "def get_top_candidates(ref_text,candidates,max=-1):\n",
    "  top_candidates = []\n",
    "  if (len(candidates) == 0):\n",
    "        return top_candidates\n",
    "  sorted_candidates = sort_by_similar(ref_text,[c['text'] for c in candidates])  \n",
    "  best_score = sorted_candidates[0]['score']\n",
    "  for index, c in enumerate(sorted_candidates):\n",
    "    if (index < max) or (c['score'] == best_score):\n",
    "        candidate = candidates[c['id']]\n",
    "        candidate['score'] = c['score']\n",
    "        top_candidates.append(candidate)\n",
    "  return top_candidates  \n",
    "\n",
    "def print_candidates(criteria,candidates):\n",
    "    print(\"## Sorted Candidates by\",criteria,\": \",[{'name':c['label'],'description':c['description'],'score':c['score']} for c in candidates])\n",
    "\n",
    "def get_resources_by_candidates(context,label,candidates,max=-1):\n",
    "  if (len(candidates) == 0):\n",
    "    return []\n",
    "  # sort candidates by name/label\n",
    "  candidates_by_name = []  \n",
    "  top_candidates_by_name = get_top_candidates(label,[ {'id':i, 'text':c['label'] } for i,c in enumerate(candidates)],10)\n",
    "  for t in top_candidates_by_name:\n",
    "    candidate = candidates[t['id']]\n",
    "    candidate['score'] = t['score']\n",
    "    candidates_by_name.append(candidate)\n",
    "  #print_candidates(\"By Name\",candidates_by_name)\n",
    "  \n",
    "  # sort candidates by properties\n",
    "  candidates_by_properties = []\n",
    "  candidate_properties = []\n",
    "  for i,c in enumerate(candidates_by_name):\n",
    "     for p in c['properties']:\n",
    "        candidate_properties.append({'id':i, 'text':p['value'] })\n",
    "  top_candidates_by_prop = get_top_candidates(context.replace(c['label'],\"\"),candidate_properties,10) \n",
    "  for t in top_candidates_by_prop:\n",
    "     candidate = candidates_by_name[t['id']]\n",
    "     if (candidate not in candidates_by_properties):\n",
    "        candidate['score'] = (2*candidate['score'] + 4*t['score']) / 6.0\n",
    "        candidates_by_properties.append(candidate)\n",
    "  #print_candidates(\"By Properties\",candidates_by_properties)\n",
    "  \n",
    "        \n",
    "  # sort candidates by description\n",
    "  candidates_by_description = []\n",
    "  top_candidates_by_desc = get_top_candidates(context.replace(c['label'],\"\"),[ {'id':i, 'text':c['description'] } for i,c in enumerate(candidates_by_properties)],max)    \n",
    "  for t in top_candidates_by_desc:\n",
    "     candidate = candidates_by_properties[t['id']]\n",
    "     if (candidate not in candidates_by_description):\n",
    "        candidate['score'] = (2*candidate['score'] + 1*t['score']) / 3.0\n",
    "        candidates_by_description.append(candidate)  \n",
    "  #print_candidates(\"By Description\",candidates_by_description)\n",
    "  return candidates_by_description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-express",
   "metadata": {
    "id": "annoying-express"
   },
   "source": [
    "## Wikidata Searching based on MediaWiki API\n",
    "\n",
    "The MediaWiki Action API is a web service that allows access to some wiki-features like authentication, page operations, and search. It can provide meta information about the wiki and the logged-in user.\n",
    "\n",
    "action=wbsearchentities\n",
    "\n",
    "Searches for entities using labels and aliases.\n",
    "\n",
    "Returns a label and description for the entity in the user language if possible. Returns details of the matched term. The matched term text is also present in the aliases key if different from the display label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8f8e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip3 install sparqlwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "u10ZrzjgfnMf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u10ZrzjgfnMf",
    "outputId": "1c56c652-8192-4f5a-dbe0-f661ebf3f4b4"
   },
   "outputs": [],
   "source": [
    "wiki_sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\",agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36')\n",
    "wiki_sparql.setReturnFormat(JSON)\n",
    "wiki_sparql.setTimeout(timeout=60)\n",
    "\n",
    "def get_wikidata_properties(entity,use_cache=False):\n",
    "  if (use_cache) and (entity in wiki_cache):\n",
    "    #print(\"use of cache!\")\n",
    "    return wiki_cache[entity].copy()\n",
    "  query = \"\"\"\n",
    "      PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "      PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "      SELECT distinct ?prop ?propLabel\n",
    "      WHERE\n",
    "      {\n",
    "        { wd:ENTITY ?a ?b }\n",
    "              union\n",
    "              { ?s ?a wd:ENTITY } .\n",
    "\n",
    "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". } \n",
    "        ?prop wikibase:directClaim ?a .\n",
    "      } \n",
    "      LIMIT 250\n",
    "      \"\"\"\n",
    "  query_text = query.replace('ENTITY',entity)\n",
    "  wiki_sparql.setQuery(query_text)\n",
    "  result = []\n",
    "  while (len(result) == 0):\n",
    "    try:\n",
    "        ret = wiki_sparql.queryAndConvert()\n",
    "        for r in ret[\"results\"][\"bindings\"]:\n",
    "            if ('propLabel' in r) and ('value' in r['propLabel']):\n",
    "                    value = r['propLabel']['value']\n",
    "                    id = r['prop']['value'].split(\"http://www.wikidata.org/entity/\")[1]\n",
    "                    if ('id' not in value.lower()) and ('link' not in value.lower()) and ('has abstract' not in value.lower()) and ('wiki' not in value.lower()) and ('instance of' not in value.lower()):\n",
    "                        result.append({'id':id, 'value':value})\n",
    "    except Exception as e:\n",
    "        print(\"Error on wikidata property query:\",e,\"->\",query_text)\n",
    "    break           \n",
    "  wiki_cache[entity] = result\n",
    "  return result\n",
    "\n",
    "def get_wikidata_candidates(label,use_cache=True,verbose=False):\n",
    "    if (use_cache) and (label in wiki_cache):\n",
    "      #print(\"use of cache for label:\",label)\n",
    "      return wiki_cache[label].copy()\n",
    "    candidates = []\n",
    "    if (label==\"\"):\n",
    "        return candidates\n",
    "    # type: One of the following values: form, form, item, lexeme, property, sense, sense\n",
    "    headers = { 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "    query_path = \"https://www.wikidata.org/w/api.php?action=wbsearchentities&search=QUERY_TEXT&language=en&limit=10&type=item&format=json\"\n",
    "    request = query_path.replace(\"QUERY_TEXT\",label)\n",
    "    if (verbose):\n",
    "        print(\"Request:\",request)\n",
    "    r = requests.get(request,headers = headers)\n",
    "    if (len(r.json()['search']) == 0):\n",
    "      if (verbose):\n",
    "        print(\"search by lemma:\",lemmatize(label))\n",
    "      r = requests.get(query_path.replace(\"QUERY_TEXT\",lemmatize(label)))\n",
    "      size = len(label.split(\" \"))\n",
    "      index = 1\n",
    "      while(('search' in r.json()) and (len(r.json()['search']) == 0) and (index<size)):\n",
    "        query_label = \" \".join(label.split(\" \")[index:])\n",
    "        index += 1  \n",
    "        if (verbose):\n",
    "          print(\"search by Partial Label:\",query_label)\n",
    "        r = requests.get(query_path.replace(\"QUERY_TEXT\",query_label)) \n",
    "    if (verbose):\n",
    "        print(\"Response:\",r.json())\n",
    "    for answer in r.json()['search']:\n",
    "        description = \"\"\n",
    "        if ('description' in answer['display']):\n",
    "          description = answer['display']['description']['value']\n",
    "          if 'disambiguation' in description:\n",
    "                continue\n",
    "        candidate = {\n",
    "            'label': answer['display']['label']['value'],\n",
    "            'id':answer['id'],\n",
    "            'description' : description,\n",
    "            'properties' : get_wikidata_properties(answer['id'],use_cache)\n",
    "        }\n",
    "        candidates.append(candidate)\n",
    "    wiki_cache[label]=candidates\n",
    "    #print(\"cache '\",label,\"' updated with:'\",[c['id'] for c in candidates])\n",
    "    return candidates\n",
    "\n",
    "def get_wikidata_resource(context,entity,max=-1,use_cache=True):\n",
    "    candidates = get_wikidata_candidates(entity,use_cache)\n",
    "    lema_entity = lemmatize(entity)\n",
    "    if (entity != lema_entity):\n",
    "        candidate_ids = [c['id'] for c in candidates]\n",
    "        for ac in get_wikidata_candidates(lema_entity,use_cache):\n",
    "            if (ac['id'] not in candidate_ids):\n",
    "                candidates.append(ac)\n",
    "    resources = get_resources_by_candidates(context, entity, candidates,max)\n",
    "    return resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76I95gPaAsfn",
   "metadata": {
    "id": "76I95gPaAsfn"
   },
   "source": [
    "## DBpedia Searching based on the Lookup Service\n",
    "\n",
    "The DBpedia Lookup is an entity retrieval service for Linked Data. It provides a straightforward solution for the frequent use case of resolving keywords and natural language to related resource identifiers in the DBpedia knowledge graph. Related means that either the label or abstract of a resource matches, or an anchor text that was frequently used in Wikipedia to refer to a specific resource matches (e.g. the resource http://dbpedia.org/resource/United_States can be looked up by the string “USA”). \n",
    "\n",
    "So whether you need an auto-complete service for your RDF application, Linked Data enhancements for your CSV tables or simply a way to retrieve specific DBpedia identifiers – the DBpedia Lookup is for you!\n",
    "\n",
    "As a part of the DBpedia Technology Stack the DBpedia Lookup can be deployed conveniently via Docker and works well with DBpedia Databus Collections. The DBpedia Lookup uses an Apache Lucene Index for resource indexing and retrieval and provides a web interface for querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "uwSFgwPRlVuN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwSFgwPRlVuN",
    "outputId": "226dbe3c-4aaa-4cc8-e379-661d5def17f6"
   },
   "outputs": [],
   "source": [
    "dbpedia_sparql = SPARQLWrapper(\"https://dbpedia.org/sparql/\")\n",
    "dbpedia_sparql.setReturnFormat(JSON)\n",
    "dbpedia_sparql.setTimeout(timeout=60)\n",
    "\n",
    "def get_dbpedia_properties(entity,use_cache=True):\n",
    "    #select distinct ?property ?label {\n",
    "      key = entity+\"_props\"\n",
    "      if (use_cache) and (key in dbpedia_cache):\n",
    "          #print(\"use of cache!\")\n",
    "          return dbpedia_cache[key].copy()\n",
    "      query = \"\"\"\n",
    "          PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "          PREFIX dbr: <http://dbpedia.org/resource/> \n",
    "          select distinct ?property ?label {\n",
    "              { <http://dbpedia.org/resource/ENTITY> ?property ?o }\n",
    "              union\n",
    "              { ?s ?property <http://dbpedia.org/resource/ENTITY> }\n",
    "\n",
    "              optional { \n",
    "                ?property rdfs:label ?label .\n",
    "                filter langMatches(lang(?label), 'en')\n",
    "              }\n",
    "              filter(regex(?property, \"property\", \"i\" )) \n",
    "          }\n",
    "          LIMIT 250\n",
    "          \"\"\"\n",
    "      query_text = query.replace('ENTITY',entity)\n",
    "      dbpedia_sparql.setQuery(query_text)\n",
    "      result = []\n",
    "      while (len(result) == 0):\n",
    "        try:\n",
    "            ret = dbpedia_sparql.queryAndConvert()\n",
    "            for r in ret[\"results\"][\"bindings\"]:\n",
    "                if ('label' in r) and ('value' in r['label']):\n",
    "                    value = r['label']['value']\n",
    "                    id = r['property']['value']\n",
    "                    if ('id' not in value.lower()) and ('link' not in value.lower()) and ('has abstract' not in value.lower()) and ('wiki' not in value.lower()) and ('instance of' not in value.lower()):\n",
    "                        result.append({'id':id, 'value':value})\n",
    "        except Exception as e:\n",
    "            print(\"Error on SPARQL query:\",e)\n",
    "        break           \n",
    "      dbpedia_cache[key] = result\n",
    "      #print(len(result),\"properties found\")\n",
    "      return result\n",
    "\n",
    "def get_dbpedia_candidates(label,use_cache=True,verbose=False):\n",
    "    if (use_cache) and (label in dbpedia_cache):\n",
    "      #print(\"use of cache!\")\n",
    "      return dbpedia_cache[label].copy()\n",
    "    candidates = []\n",
    "    if (label==\"\"):\n",
    "        return candidates\n",
    "    # type: One of the following values: form, form, item, lexeme, property, sense, sense\n",
    "    #query_path = \"https://www.wikidata.org/w/api.php?action=wbsearchentities&search=QUERY_TEXT&language=en&limit=10&type=item&format=json\"\n",
    "    query_path = \"https://lookup.dbpedia.org/api/search?format=JSON&query=QUERY_TEXT&maxResults=10\"\n",
    "    url = query_path.replace(\"QUERY_TEXT\",label)\n",
    "    #print(\"->\",url)\n",
    "    r = requests.get(url)\n",
    "    if (len(r.json()['docs']) == 0):\n",
    "        if (verbose):\n",
    "            print(\"Use of lemmatize literal:\",lemmatize(label))\n",
    "        r = requests.get(query_path.replace(\"QUERY_TEXT\",lemmatize(label)))\n",
    "        size = len(label.split(\" \"))\n",
    "        index = 1  \n",
    "        while(('search' in r.json()) and (len(r.json()['search']) == 0) and (index<size)):\n",
    "            query_label = \" \".join(label.split(\" \")[index:])\n",
    "            index += 1  \n",
    "            if (verbose):\n",
    "              print(\"search by Partial Label:\",query_label)\n",
    "            r = requests.get(query_path.replace(\"QUERY_TEXT\",query_label)) \n",
    "    for answer in r.json()['docs']:\n",
    "        description,label,id = \"\",\"\",\"\"\n",
    "        properties = []\n",
    "        if ('comment' in answer) and (len(answer['comment']) > 0):\n",
    "          description = answer['comment'][0].replace(\"<B>\",\"\").replace(\"</B>\",\"\")\n",
    "        if ('resource' in answer) and (len(answer['resource']) > 0):\n",
    "          id = answer['resource'][0].split(\"http://dbpedia.org/resource/\")[1]\n",
    "          properties = get_dbpedia_properties(id,use_cache)\n",
    "        if ('label' in answer) and (len(answer['label']) > 0):\n",
    "          label = answer['label'][0].replace(\"<B>\",\"\").replace(\"</B>\",\"\")\n",
    "        else:\n",
    "          label = id        \n",
    "        candidate = {\n",
    "            'label': label,\n",
    "            'id':id,\n",
    "            'description' : description,\n",
    "            'properties' : properties\n",
    "        }\n",
    "        candidates.append(candidate)\n",
    "    dbpedia_cache[label]=candidates\n",
    "    return candidates\n",
    "\n",
    "def get_dbpedia_resource(context,entity,max=-1,use_cache=True):\n",
    "    candidates = get_dbpedia_candidates(entity,use_cache)\n",
    "    lema_entity = lemmatize(entity)\n",
    "    if (entity != lema_entity):\n",
    "        candidate_ids = [c['id'] for c in candidates]\n",
    "        for ac in get_dbpedia_candidates(lema_entity,use_cache):\n",
    "            if (ac['id'] not in candidate_ids):\n",
    "                candidates.append(ac)\n",
    "    resources = get_resources_by_candidates(context, entity, candidates,max)\n",
    "    return resources   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-victory",
   "metadata": {
    "id": "comparable-victory"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8r4_O_VKUq",
   "metadata": {
    "id": "ee8r4_O_VKUq"
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HNrfwq21VLpu",
   "metadata": {
    "id": "HNrfwq21VLpu"
   },
   "source": [
    "### SimpleQuestions Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vYys9IuHaTXO",
   "metadata": {
    "id": "vYys9IuHaTXO"
   },
   "source": [
    "#### Wikidata SimpleQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "finite-hypothesis",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "finite-hypothesis",
    "outputId": "80223f82-e277-4bd6-9428-c1d4a5085be3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "      <th>resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where did roger marquis die</td>\n",
       "      <td>[Roger Marquis]</td>\n",
       "      <td>[Q7358590]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what was the cause of death of yves klein</td>\n",
       "      <td>[Yves Klein]</td>\n",
       "      <td>[Q154335]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What position does carlos gomez play?</td>\n",
       "      <td>[Carlos Gómez]</td>\n",
       "      <td>[Q2747238]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how does engelbert zaschka identify</td>\n",
       "      <td>[Engelbert Zaschka]</td>\n",
       "      <td>[Q62498]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what position does pee wee reese play in baseball</td>\n",
       "      <td>[Pee Wee Reese]</td>\n",
       "      <td>[Q182485]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question             entities  \\\n",
       "0                        Where did roger marquis die      [Roger Marquis]   \n",
       "1          what was the cause of death of yves klein         [Yves Klein]   \n",
       "2              What position does carlos gomez play?       [Carlos Gómez]   \n",
       "3               how does engelbert zaschka identify   [Engelbert Zaschka]   \n",
       "4  what position does pee wee reese play in baseball      [Pee Wee Reese]   \n",
       "\n",
       "    resources  \n",
       "0  [Q7358590]  \n",
       "1   [Q154335]  \n",
       "2  [Q2747238]  \n",
       "3    [Q62498]  \n",
       "4   [Q182485]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/wsq-labels.csv', index_col=0)\n",
    "wsq_df = df.drop(['predicate','object','predicate_label','object_label'], axis=1)\n",
    "wsq_df = wsq_df.rename(columns = {'subject':'resources','subject_label':'entities'})\n",
    "wsq_df = wsq_df[['question','entities','resources']]\n",
    "wsq_df['entities'] = [ [e] for e in wsq_df['entities'].tolist()]\n",
    "wsq_df['resources'] = [ [e] for e in wsq_df['resources'].tolist()]\n",
    "wsq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ba87391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "      <th>resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5622</td>\n",
       "      <td>5622</td>\n",
       "      <td>5622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5605</td>\n",
       "      <td>5161</td>\n",
       "      <td>5189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Name an actor.</td>\n",
       "      <td>[drama film]</td>\n",
       "      <td>[Q130232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              question      entities  resources\n",
       "count             5622          5622       5622\n",
       "unique            5605          5161       5189\n",
       "top     Name an actor.  [drama film]  [Q130232]\n",
       "freq                 6            25         25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsq_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Np4sKzSbaVaG",
   "metadata": {
    "id": "Np4sKzSbaVaG"
   },
   "source": [
    "#### DBpedia SimpleQuestions\n",
    "\n",
    "From paper: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8de58018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
      "     |████████████████████████████████| 235 kB 1.3 MB/s            \n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "vG5FDueoaeqL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "vG5FDueoaeqL",
    "outputId": "30cca5db-e954-46d7-bbc5-b0cec40bb8f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 8595 Counter: 3688 Ref Size: 5622\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "      <th>resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where did roger marquis die</td>\n",
       "      <td>[Roger Marquis]</td>\n",
       "      <td>[Roger_Marquis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What position does carlos gomez play?</td>\n",
       "      <td>[Carlos Gomez]</td>\n",
       "      <td>[Carlos_Gómez]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how does engelbert zaschka identify</td>\n",
       "      <td>[Engelbert Zaschka]</td>\n",
       "      <td>[Engelbert_Zaschka]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what position does pee wee reese play in baseball</td>\n",
       "      <td>[Pee Wee Reese]</td>\n",
       "      <td>[Pee_Wee_Reese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which Swiss conductor's cause of death is myoc...</td>\n",
       "      <td>[Myocardial infarction]</td>\n",
       "      <td>[Myocardial_infarction]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question                 entities  \\\n",
       "0                        Where did roger marquis die          [Roger Marquis]   \n",
       "1              What position does carlos gomez play?           [Carlos Gomez]   \n",
       "2                how does engelbert zaschka identify      [Engelbert Zaschka]   \n",
       "3  what position does pee wee reese play in baseball          [Pee Wee Reese]   \n",
       "4  Which Swiss conductor's cause of death is myoc...  [Myocardial infarction]   \n",
       "\n",
       "                 resources  \n",
       "0          [Roger_Marquis]  \n",
       "1           [Carlos_Gómez]  \n",
       "2      [Engelbert_Zaschka]  \n",
       "3          [Pee_Wee_Reese]  \n",
       "4  [Myocardial_infarction]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request as url\n",
    "import json\n",
    "import unidecode\n",
    "\n",
    "\n",
    "def normalize(label):\n",
    "  return unidecode.unidecode(label.strip())\n",
    "\n",
    "\n",
    "stream = url.urlopen(\"https://raw.githubusercontent.com/castorini/SimpleDBpediaQA/master/V1/test.json\")\n",
    "content = stream.read()\n",
    "data = json.loads(content)\n",
    "ref_questions = [e.lower().strip() for e in pd.read_csv('data/wsq-labels.csv', index_col=0)['question'].tolist()]\n",
    "counter = 0\n",
    "total = 0\n",
    "rows = []\n",
    "for question in data['Questions']:\n",
    "  total += 1\n",
    "  if (question['Query'].lower().strip() in ref_questions):\n",
    "    counter += 1\n",
    "    row = {\n",
    "        'question':question['Query'],\n",
    "        'entities':[normalize(question['Subject'].split(\"http://dbpedia.org/resource/\")[1].replace(\"_\",\" \"))],\n",
    "        'resources':[question['Subject'].split(\"http://dbpedia.org/resource/\")[1]],\n",
    "    }\n",
    "    rows.append(row)\n",
    "print(\"Total:\",total,\"Counter:\",counter,\"Ref Size:\",len(ref_questions))\n",
    "dsq_df = pd.DataFrame(rows)\n",
    "dsq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14a45203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "      <th>resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3688</td>\n",
       "      <td>3688</td>\n",
       "      <td>3688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3656</td>\n",
       "      <td>3420</td>\n",
       "      <td>3420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Name an actor.</td>\n",
       "      <td>[Actor]</td>\n",
       "      <td>[Actor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              question entities resources\n",
       "count             3688     3688      3688\n",
       "unique            3656     3420      3420\n",
       "top     Name an actor.  [Actor]   [Actor]\n",
       "freq                12       25        25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsq_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u0HBoh39X-Xs",
   "metadata": {
    "id": "u0HBoh39X-Xs"
   },
   "source": [
    "### WikidataQA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8_OsbKedYAie",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "8_OsbKedYAie",
    "outputId": "8feb4ae9-52e4-4b65-e081-1714aa4e7a1c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "      <th>resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the president of Poland?</td>\n",
       "      <td>[president of Poland]</td>\n",
       "      <td>[Q1054799]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many Turing awards have people from Austri...</td>\n",
       "      <td>[Turing awards,  Austria]</td>\n",
       "      <td>[Q185667,  Q40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Give me all countries that have won a FIFA Wor...</td>\n",
       "      <td>[FIFA World Cup]</td>\n",
       "      <td>[Q19317]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the population of Chile?</td>\n",
       "      <td>[Chile]</td>\n",
       "      <td>[Q298]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is the author of One Piece?</td>\n",
       "      <td>[One Piece]</td>\n",
       "      <td>[Q673]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                    Who is the president of Poland?   \n",
       "1  How many Turing awards have people from Austri...   \n",
       "2  Give me all countries that have won a FIFA Wor...   \n",
       "3                   What is the population of Chile?   \n",
       "4                    Who is the author of One Piece?   \n",
       "\n",
       "                    entities        resources  \n",
       "0      [president of Poland]       [Q1054799]  \n",
       "1  [Turing awards,  Austria]  [Q185667,  Q40]  \n",
       "2           [FIFA World Cup]         [Q19317]  \n",
       "3                    [Chile]           [Q298]  \n",
       "4                [One Piece]           [Q673]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_values(text):\n",
    "  return text.replace('\\'',\"\").replace(\"[\",\"\").replace(\"]\",\"\").split(\",\")\n",
    "\n",
    "df = pd.read_csv('data/wqa-labels.csv', index_col=0)\n",
    "wqa_df = df.drop(['predicates','objects','predicate_labels','object_labels'], axis=1)\n",
    "wqa_df = wqa_df.rename(columns = {'subjects':'resources','subject_labels':'entities'})\n",
    "wqa_df = wqa_df[['question','entities','resources']]\n",
    "wqa_df['entities'] = [ split_values(e) for e in wqa_df['entities'].tolist()]\n",
    "wqa_df['resources'] = [ split_values(e) for e in wqa_df['resources'].tolist()]\n",
    "wqa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf5b4a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "      <th>resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>101</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Who is the president of Poland?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               question entities resources\n",
       "count                               101      101       101\n",
       "unique                              101       95        95\n",
       "top     Who is the president of Poland?       []        []\n",
       "freq                                  1        4         4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wqa_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qbby_0brtpot",
   "metadata": {
    "id": "qbby_0brtpot"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "TgxmYuaatrQF",
   "metadata": {
    "id": "TgxmYuaatrQF"
   },
   "outputs": [],
   "source": [
    "def normalize(label):\n",
    "  return label.strip()\n",
    "\n",
    "def precision(tp,fp):\n",
    "  if (fp+tp == 0):\n",
    "    return 0.0\n",
    "  return tp / (fp + tp)\n",
    "\n",
    "def recall(tp,fn):\n",
    "  if (fn+tp == 0):\n",
    "    return 0.0\n",
    "  return tp / (fn + tp)\n",
    "\n",
    "def f1(tp,fp,fn):\n",
    "  p = precision(tp,fp)\n",
    "  r = recall(tp,fn)\n",
    "  if (p+r == 0):\n",
    "    return 0.0\n",
    "  return 2 * ((p*r)/(p+r))\n",
    "\n",
    "def average(values):\n",
    "  return sum(values) / len(values) \n",
    "\n",
    "# lists of entity lists\n",
    "def evaluate_labels(true_list,pred_list):\n",
    "  tp, tn, fp, fn = 0, 0, 0, 0\n",
    "  precision_list, recall_list, f1_list = [], [], []\n",
    "  empty_values = 0\n",
    "  for index in range(len(true_list)):\n",
    "    # normalize entities\n",
    "    valid_entities = [normalize(e) for e in true_list[index] if e != '']\n",
    "    predicted_entities = [normalize(e) for e in pred_list[index]]\n",
    "    ptp, ptn, pfp, pfn = 0, 0, 0, 0\n",
    "    if (len(valid_entities)==0):\n",
    "      empty_values += 1\n",
    "    for entity in valid_entities:\n",
    "      if (entity not in predicted_entities):\n",
    "        pfn += 1\n",
    "    for entity in predicted_entities:\n",
    "      if (entity in valid_entities):\n",
    "        ptp += 1\n",
    "      else:\n",
    "        pfp += 1    \n",
    "    precision_list.append(precision(ptp,pfp))\n",
    "    recall_list.append(recall(ptp,pfn))\n",
    "    f1_list.append(f1(ptp,pfp,pfn))\n",
    "    tp += ptp\n",
    "    tn += ptn\n",
    "    fp += pfp\n",
    "    fn += pfn  \n",
    "  return  {\n",
    "      'total': index,\n",
    "      'empty': empty_values,\n",
    "      'tp': tp,\n",
    "      'tn': tn, \n",
    "      'fp': fp,\n",
    "      'fn':fn,\n",
    "      'micro-precision': precision(tp,fp),\n",
    "      'micro-recall': recall(tp,fn),\n",
    "      'micro-f1': f1(tp,fp,fn),\n",
    "      'macro-precision': average(precision_list),\n",
    "      'macro-recall': average(recall_list),\n",
    "      'macro-f1': average(f1_list)\n",
    "  }  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qOSX-DKgc02r",
   "metadata": {
    "id": "qOSX-DKgc02r"
   },
   "source": [
    "## SOTA Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2pKfdROVfRVX",
   "metadata": {
    "id": "2pKfdROVfRVX"
   },
   "source": [
    "### DBpedia Spotlight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nACqO807fWW3",
   "metadata": {
    "id": "nACqO807fWW3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install spacy-dbpedia-spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dd2c65cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: numpy in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (1.21.4)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.22.3-cp39-cp39-macosx_11_0_arm64.whl (12.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.4\n",
      "    Uninstalling numpy-1.21.4:\n",
      "      Successfully uninstalled numpy-1.21.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-core-web-sm 3.2.0 requires spacy<3.3.0,>=3.2.0, but you have spacy 3.0.6 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.22.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78796244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Swiss', 'id': 'Switzerland', 'score': '0.9724504598633273'}, {'label': 'conductor', 'id': 'Conducting', 'score': '0.9962600187612703'}, {'label': 'infarction', 'id': 'Infarction', 'score': '0.983796696254073'}]\n",
      "use of spotlight cache!\n",
      "['Switzerland', 'Conducting', 'Infarction']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "lang = \"en\"\n",
    "spacy_nlp = spacy.blank(lang)\n",
    "spacy_nlp.add_pipe('dbpedia_spotlight', config={'confidence': 0.4, 'overwrite_ents':False, 'language_code': lang})\n",
    "\n",
    "\n",
    "spotlight_cache = {}\n",
    "def get_resources_by_dbpedia_spotlight(query,entities=[]):\n",
    "  key = query.replace(\" \",\"_\")  \n",
    "  if (key in spotlight_cache):\n",
    "        print(\"use of spotlight cache!\")\n",
    "        return spotlight_cache[key]\n",
    "  doc = spacy_nlp(query)\n",
    "  resources = []\n",
    "  for ent in doc.spans['dbpedia_spotlight']:\n",
    "    uri = ent.kb_id_.split(\"/\")\n",
    "    resources.append({\n",
    "        'label': ent.text,\n",
    "        'id': uri[len(uri)-1],\n",
    "        'score': ent._.dbpedia_raw_result['@similarityScore']\n",
    "    })\n",
    "  spotlight_cache[key]=resources\n",
    "  return resources\n",
    "\n",
    "def retrieve_resources_by_dbpedia_spotlight(query,entities=[]):\n",
    "  return [ r['id'] for r in  get_resources_by_dbpedia_spotlight(query,entities)]\n",
    "\n",
    "print(get_resources_by_dbpedia_spotlight(\"Which Swiss conductor's cause of death is myocardial infarction?\"))\n",
    "print(retrieve_resources_by_dbpedia_spotlight(\"Which Swiss conductor's cause of death is myocardial infarction?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OsI0X3Cdzy-0",
   "metadata": {
    "id": "OsI0X3Cdzy-0"
   },
   "source": [
    "### Wikipedia Entity Linker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "V85r0M_-z2B6",
   "metadata": {
    "id": "V85r0M_-z2B6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install spacy-entity-linker\n",
    "!python -m spacy_entity_linker \"download_knowledge_base\"\n",
    "!pip install spacy==3.0.6\n",
    "!python -m spacy download en_core_web_sm\n",
    "# require restart runtime!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "t2huRBP60BbX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2huRBP60BbX",
    "outputId": "e41f6a90-8df0-4675-d18e-a347142423a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Pirates of the Caribbean', 'id': 'Q194318', 'score': -1}, {'label': 'Caribbean', 'id': 'Q664609', 'score': -1}, {'label': 'Silvester', 'id': 'Q12525597', 'score': -1}]\n",
      "use of wel cache!\n",
      "['Q194318', 'Q664609', 'Q12525597']\n"
     ]
    }
   ],
   "source": [
    "import spacy  # version 3.0.6'\n",
    "\n",
    "# initialize language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# add pipeline (declared through entry_points in setup.py)\n",
    "nlp.add_pipe(\"entityLinker\", last=True)\n",
    "\n",
    "wel_cache = {}\n",
    "def get_resources_by_wikidata_entity_linking(query,entities=[]):\n",
    "  key = query.replace(\" \",\"_\")  \n",
    "  if (key in wel_cache):\n",
    "        print(\"use of wel cache!\")\n",
    "        return wel_cache[key]\n",
    "  doc = nlp(query)  \n",
    "  # returns all entities in the whole document\n",
    "  all_linked_entities = doc._.linkedEntities\n",
    "  # iterates over sentences and prints linked entities\n",
    "  resources = []\n",
    "  for sent in doc.sents:\n",
    "    for i in sent._.linkedEntities:\n",
    "      resources.append({\n",
    "          'label':i.label,\n",
    "          'id':\"Q\"+str(i.identifier),\n",
    "          'score':-1\n",
    "      })      \n",
    "    #sent._.linkedEntities.pretty_print()\n",
    "  wel_cache[key] = resources\n",
    "  return resources\n",
    "\n",
    "def retrieve_resources_by_wikidata_entity_linking(query,entities=[]):\n",
    "  return [ r['id'] for r in  get_resources_by_wikidata_entity_linking(query,entities)]\n",
    "\n",
    "print(get_resources_by_wikidata_entity_linking(\"I watched the Pirates of the Caribbean last silvester\"))\n",
    "print(retrieve_resources_by_wikidata_entity_linking(\"I watched the Pirates of the Caribbean last silvester\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jeSuxIoXt-P6",
   "metadata": {
    "id": "jeSuxIoXt-P6"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mYvWhU0Tt_SL",
   "metadata": {
    "id": "mYvWhU0Tt_SL"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def json_file(name):\n",
    "  return name+\"-resources.json\"\n",
    "\n",
    "def csv_file(name):\n",
    "  return name+\"-resources.csv\"\n",
    "\n",
    "def retrieve_wikidata_candidates(query,entities,use_cache=True):\n",
    "  resources = []\n",
    "  for e in entities:\n",
    "    for r in get_wikidata_candidates(e,use_cache):\n",
    "      resources.append(r['id'])\n",
    "  return resources\n",
    "\n",
    "def retrieve_wikidata_resources(query,entities,max=-1,use_cache=True):\n",
    "  resources = []\n",
    "  for e in entities:\n",
    "    for r in get_wikidata_resource(query,e,max,use_cache):\n",
    "      resources.append(r['id'])\n",
    "  return resources\n",
    "\n",
    "def evaluate_wiki_data(name,dataframe, max=-1):\n",
    "  l1, l2, l3,l4, l5, l6 = [], [], [], [], [], []\n",
    "  total = 0\n",
    "  for index, row in dataframe.iterrows():\n",
    "      if (max != -1) and (total > max):\n",
    "        break\n",
    "      question = row['question']\n",
    "      entities = row['entities']\n",
    "      print(index,\":\",question)\n",
    "      l1.append(retrieve_wikidata_candidates(question,entities))\n",
    "      l2.append(retrieve_wikidata_resources(question,entities))\n",
    "      l3.append(retrieve_wikidata_resources(question,entities,1))\n",
    "      l4.append(retrieve_wikidata_resources(question,entities,2))\n",
    "      l5.append(retrieve_wikidata_resources(question,entities,3))  \n",
    "      l6.append(retrieve_resources_by_wikidata_entity_linking(question,entities))      \n",
    "      total += 1\n",
    "  dataframe['MuHeQA_Cand']=l1\n",
    "  dataframe['MuHeQA_Rank']=l2\n",
    "  dataframe['MuHeQA_Top1']=l3\n",
    "  dataframe['MuHeQA_Top2']=l4\n",
    "  dataframe['MuHeQA_Top3']=l5\n",
    "  dataframe['WEL']=l6  \n",
    "  clear_output(wait=True)\n",
    "  print(total,\"questions analyzed!\")\n",
    "  dataframe.to_json(json_file(name), orient='split')\n",
    "  dataframe.to_csv(csv_file(name))\n",
    "  return dataframe\n",
    "\n",
    "def retrieve_dbpedia_candidates(query,entities,use_cache=True):\n",
    "  resources = []\n",
    "  for e in entities:\n",
    "    for r in get_dbpedia_candidates(e,use_cache):\n",
    "      resources.append(r['id'])\n",
    "  return resources\n",
    "\n",
    "def retrieve_dbpedia_resources(query,entities,max=-1,use_cache=True):\n",
    "  resources = []\n",
    "  for e in entities:\n",
    "    for r in get_dbpedia_resource(query,e,max,use_cache):\n",
    "      resources.append(r['id'])\n",
    "  return resources\n",
    "\n",
    "\n",
    "def evaluate_dbpedia_data(name,dataframe,max=-1):\n",
    "  l1, l2, l3, l4, l5, l6 = [], [], [], [], [], []\n",
    "  total = 0\n",
    "  for index, row in dataframe.iterrows():\n",
    "      if (max != -1) and (total > max):\n",
    "        break\n",
    "      question = row['question']\n",
    "      entities = row['entities']\n",
    "      print(index,\":\",question)\n",
    "      l1.append(retrieve_dbpedia_candidates(question,entities))\n",
    "      l2.append(retrieve_dbpedia_resources(question,entities))\n",
    "      l3.append(retrieve_dbpedia_resources(question,entities,1))\n",
    "      l4.append(retrieve_dbpedia_resources(question,entities,2))\n",
    "      l5.append(retrieve_dbpedia_resources(question,entities,3))    \n",
    "      l6.append(retrieve_resources_by_dbpedia_spotlight(question,entities))      \n",
    "      total += 1\n",
    "  dataframe['MuHeQA_Cand']=l1\n",
    "  dataframe['MuHeQA_Rank']=l2\n",
    "  dataframe['MuHeQA_Top1']=l3\n",
    "  dataframe['MuHeQA_Top2']=l4\n",
    "  dataframe['MuHeQA_Top3']=l5\n",
    "  dataframe['Spotlight']=l6\n",
    "  clear_output(wait=True)\n",
    "  print(total,\"questions analyzed!\")\n",
    "  dataframe.to_json(json_file(name), orient='split')\n",
    "  dataframe.to_csv(csv_file(name))\n",
    "  return dataframe\n",
    "\n",
    "def make_report(name,additional=[]):\n",
    "  \n",
    "  df = pd.read_json(json_file(name), orient='split')\n",
    "  y_true =df['resources'].tolist()\n",
    "  results = []\n",
    "  for col in df.columns:\n",
    "    if (col == 'question') or (col == 'entities') or (col == 'resources'):\n",
    "      continue\n",
    "    y_pred = df[col].tolist()\n",
    "    result = evaluate_labels(y_true,y_pred)\n",
    "    result['model']=col\n",
    "    results.append(result)\n",
    "\n",
    "  for row in additional:\n",
    "    results.append(row)\n",
    "\n",
    "  df_results = pd.DataFrame(results)\n",
    "  return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db49769a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikidata Candidates: ['Q1517084', 'Q3631400', 'Q7750866', 'Q26842045', 'Q7750863', 'Q27711957', 'Q27711998', 'Q27709884', 'Q22122164']\n",
      "Wikidata Resources: ['Q7750866']\n",
      "Wikidata Linking: ['Q315', 'Q1201260']\n",
      "DBpedia Candidates: ['Doctor_of_Medicine', 'Combat_medic', 'SS_Medic', 'Medic', 'Chaplain–Medic_massacre', 'Street_medic', 'Mass_media', 'The_Medic', 'Medic_(TV_series)', 'The_Medic_Droid']\n",
      "DBpedia Resources: ['Medic_(TV_series)']\n",
      "DBpedia Spotlight: ['Language', 'Medic']\n"
     ]
    }
   ],
   "source": [
    "question = \"what language is spoken in the medic\"\n",
    "entities = [\"the medic\"]\n",
    "    \n",
    "print(\"Wikidata Candidates:\",retrieve_wikidata_candidates(question,entities))\n",
    "print(\"Wikidata Resources:\",retrieve_wikidata_resources(question,entities))\n",
    "print(\"Wikidata Linking:\",retrieve_resources_by_wikidata_entity_linking(question,entities))\n",
    "print(\"DBpedia Candidates:\",retrieve_dbpedia_candidates(question,entities,use_cache=False))\n",
    "print(\"DBpedia Resources:\",retrieve_dbpedia_resources(question,entities,use_cache=False))\n",
    "print(\"DBpedia Spotlight:\",retrieve_resources_by_dbpedia_spotlight(question,entities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bf556368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "so = open(\"out.log\", 'w', 10)\n",
    "sys.stdout.echo = so\n",
    "sys.stderr.echo = so\n",
    "\n",
    "get_ipython().log.handlers[0].stream = so\n",
    "get_ipython().log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kvl_DgIw5FH3",
   "metadata": {
    "id": "Kvl_DgIw5FH3"
   },
   "source": [
    "## SimpleQuestions Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vOUzDnCe8BHe",
   "metadata": {
    "id": "vOUzDnCe8BHe"
   },
   "source": [
    "### Wikidata SimpleQuestions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wWbT8K-Z6QQt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 713
    },
    "id": "wWbT8K-Z6QQt",
    "outputId": "1ec8c2dd-37e5-415f-d82c-24d949af8e07"
   },
   "outputs": [],
   "source": [
    "evaluate_wiki_data('wsq',wsq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vCSzaTTs6XpZ",
   "metadata": {
    "id": "vCSzaTTs6XpZ"
   },
   "outputs": [],
   "source": [
    "make_report('wsq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFFMdux78EoU",
   "metadata": {
    "id": "oFFMdux78EoU"
   },
   "source": [
    "### DBpedia SimpleQuestions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "l4AKe1Ju8Ie5",
   "metadata": {
    "id": "l4AKe1Ju8Ie5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3688 questions analyzed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "      <th>resources</th>\n",
       "      <th>MuHeQA_Cand</th>\n",
       "      <th>MuHeQA_Rank</th>\n",
       "      <th>MuHeQA_Top1</th>\n",
       "      <th>MuHeQA_Top2</th>\n",
       "      <th>MuHeQA_Top3</th>\n",
       "      <th>Spotlight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where did roger marquis die</td>\n",
       "      <td>[Roger Marquis]</td>\n",
       "      <td>[Roger_Marquis]</td>\n",
       "      <td>[Roger_Marquis,_2nd_Earl_of_Woolton, Ça_Ira_(o...</td>\n",
       "      <td>[Roger_Marquis]</td>\n",
       "      <td>[Roger_Marquis]</td>\n",
       "      <td>[Roger_Marquis]</td>\n",
       "      <td>[Roger_Marquis]</td>\n",
       "      <td>[Roger_Marquis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What position does carlos gomez play?</td>\n",
       "      <td>[Carlos Gomez]</td>\n",
       "      <td>[Carlos_Gómez]</td>\n",
       "      <td>[Carlos_Gomes_Júnior, Juan_Carlos_Gómez, Carlo...</td>\n",
       "      <td>[Carlos_Gómez]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Scott_Gomez]</td>\n",
       "      <td>[Scott_Gomez]</td>\n",
       "      <td>[Carlos_Gómez]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how does engelbert zaschka identify</td>\n",
       "      <td>[Engelbert Zaschka]</td>\n",
       "      <td>[Engelbert_Zaschka]</td>\n",
       "      <td>[Engelbert_Zaschka]</td>\n",
       "      <td>[Engelbert_Zaschka]</td>\n",
       "      <td>[Engelbert_Zaschka]</td>\n",
       "      <td>[Engelbert_Zaschka]</td>\n",
       "      <td>[Engelbert_Zaschka]</td>\n",
       "      <td>[Engelbert_Zaschka]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what position does pee wee reese play in baseball</td>\n",
       "      <td>[Pee Wee Reese]</td>\n",
       "      <td>[Pee_Wee_Reese]</td>\n",
       "      <td>[Pee_Wee_Reese, American_Amateur_Baseball_Cong...</td>\n",
       "      <td>[Pee_Wee_Reese]</td>\n",
       "      <td>[Pee_Wee_Reese]</td>\n",
       "      <td>[Pee_Wee_Reese]</td>\n",
       "      <td>[Pee_Wee_Reese]</td>\n",
       "      <td>[Pee_Wee_Reese, Urine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which Swiss conductor's cause of death is myoc...</td>\n",
       "      <td>[Myocardial infarction]</td>\n",
       "      <td>[Myocardial_infarction]</td>\n",
       "      <td>[Myocardial_infarction, Myocardial_infarction_...</td>\n",
       "      <td>[Myocardial_infarction]</td>\n",
       "      <td>[Myocardial_infarction]</td>\n",
       "      <td>[Myocardial_infarction]</td>\n",
       "      <td>[Myocardial_infarction]</td>\n",
       "      <td>[Switzerland, Conducting, Infarction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>What country was malouf abraham, sr. born to</td>\n",
       "      <td>[Malouf Abraham, Sr.]</td>\n",
       "      <td>[Malouf_Abraham,_Sr.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Abraham, Serbian_language]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>is zhang ziyi female or male</td>\n",
       "      <td>[Zhang Ziyi]</td>\n",
       "      <td>[Zhang_Ziyi]</td>\n",
       "      <td>[Zhang_Ziyi, Ziyu_Zhang, List_of_awards_and_no...</td>\n",
       "      <td>[Zhang_Ziyi]</td>\n",
       "      <td>[Zhang_Ziyi]</td>\n",
       "      <td>[Zhang_Ziyi]</td>\n",
       "      <td>[Zhang_Ziyi]</td>\n",
       "      <td>[Zhang_Ziyi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>What genre is the book circle of friends?</td>\n",
       "      <td>[Circle of Friends (novel)]</td>\n",
       "      <td>[Circle_of_Friends_(novel)]</td>\n",
       "      <td>[Circle_of_Friends_(novel), Dōjin, Neil_LaBute...</td>\n",
       "      <td>[Circle_of_Friends_(novel)]</td>\n",
       "      <td>[Circle_of_Friends_(novel)]</td>\n",
       "      <td>[Circle_of_Friends_(novel)]</td>\n",
       "      <td>[Circle_of_Friends_(novel)]</td>\n",
       "      <td>[Circle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>Who is a notable figure that was born in barce...</td>\n",
       "      <td>[Barcelona]</td>\n",
       "      <td>[Barcelona]</td>\n",
       "      <td>[Barcelona, FC_Barcelona, FC_Barcelona_B, Prov...</td>\n",
       "      <td>[Barcelona]</td>\n",
       "      <td>[Barcelona]</td>\n",
       "      <td>[Barcelona]</td>\n",
       "      <td>[Barcelona]</td>\n",
       "      <td>[Barcelona]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>Where was gunnar johansen born in Denmark?</td>\n",
       "      <td>[Gunnar Johansen]</td>\n",
       "      <td>[Gunnar_Johansen]</td>\n",
       "      <td>[Gunnar_Johansson-Säwensten, Gunnar_Johansson_...</td>\n",
       "      <td>[Gunnar_Johansen]</td>\n",
       "      <td>[Gunnar_Johansen]</td>\n",
       "      <td>[Gunnar_Johansen]</td>\n",
       "      <td>[Gunnar_Johansen]</td>\n",
       "      <td>[Gunnar_Johansen, Denmark]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3688 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0                           Where did roger marquis die   \n",
       "1                 What position does carlos gomez play?   \n",
       "2                   how does engelbert zaschka identify   \n",
       "3     what position does pee wee reese play in baseball   \n",
       "4     Which Swiss conductor's cause of death is myoc...   \n",
       "...                                                 ...   \n",
       "3683       What country was malouf abraham, sr. born to   \n",
       "3684                       is zhang ziyi female or male   \n",
       "3685          What genre is the book circle of friends?   \n",
       "3686  Who is a notable figure that was born in barce...   \n",
       "3687         Where was gunnar johansen born in Denmark?   \n",
       "\n",
       "                         entities                    resources  \\\n",
       "0                 [Roger Marquis]              [Roger_Marquis]   \n",
       "1                  [Carlos Gomez]               [Carlos_Gómez]   \n",
       "2             [Engelbert Zaschka]          [Engelbert_Zaschka]   \n",
       "3                 [Pee Wee Reese]              [Pee_Wee_Reese]   \n",
       "4         [Myocardial infarction]      [Myocardial_infarction]   \n",
       "...                           ...                          ...   \n",
       "3683        [Malouf Abraham, Sr.]        [Malouf_Abraham,_Sr.]   \n",
       "3684                 [Zhang Ziyi]                 [Zhang_Ziyi]   \n",
       "3685  [Circle of Friends (novel)]  [Circle_of_Friends_(novel)]   \n",
       "3686                  [Barcelona]                  [Barcelona]   \n",
       "3687            [Gunnar Johansen]            [Gunnar_Johansen]   \n",
       "\n",
       "                                            MuHeQA_Cand  \\\n",
       "0     [Roger_Marquis,_2nd_Earl_of_Woolton, Ça_Ira_(o...   \n",
       "1     [Carlos_Gomes_Júnior, Juan_Carlos_Gómez, Carlo...   \n",
       "2                                   [Engelbert_Zaschka]   \n",
       "3     [Pee_Wee_Reese, American_Amateur_Baseball_Cong...   \n",
       "4     [Myocardial_infarction, Myocardial_infarction_...   \n",
       "...                                                 ...   \n",
       "3683                                                 []   \n",
       "3684  [Zhang_Ziyi, Ziyu_Zhang, List_of_awards_and_no...   \n",
       "3685  [Circle_of_Friends_(novel), Dōjin, Neil_LaBute...   \n",
       "3686  [Barcelona, FC_Barcelona, FC_Barcelona_B, Prov...   \n",
       "3687  [Gunnar_Johansson-Säwensten, Gunnar_Johansson_...   \n",
       "\n",
       "                      MuHeQA_Rank                  MuHeQA_Top1  \\\n",
       "0                 [Roger_Marquis]              [Roger_Marquis]   \n",
       "1                  [Carlos_Gómez]                           []   \n",
       "2             [Engelbert_Zaschka]          [Engelbert_Zaschka]   \n",
       "3                 [Pee_Wee_Reese]              [Pee_Wee_Reese]   \n",
       "4         [Myocardial_infarction]      [Myocardial_infarction]   \n",
       "...                           ...                          ...   \n",
       "3683                           []                           []   \n",
       "3684                 [Zhang_Ziyi]                 [Zhang_Ziyi]   \n",
       "3685  [Circle_of_Friends_(novel)]  [Circle_of_Friends_(novel)]   \n",
       "3686                  [Barcelona]                  [Barcelona]   \n",
       "3687            [Gunnar_Johansen]            [Gunnar_Johansen]   \n",
       "\n",
       "                      MuHeQA_Top2                  MuHeQA_Top3  \\\n",
       "0                 [Roger_Marquis]              [Roger_Marquis]   \n",
       "1                   [Scott_Gomez]                [Scott_Gomez]   \n",
       "2             [Engelbert_Zaschka]          [Engelbert_Zaschka]   \n",
       "3                 [Pee_Wee_Reese]              [Pee_Wee_Reese]   \n",
       "4         [Myocardial_infarction]      [Myocardial_infarction]   \n",
       "...                           ...                          ...   \n",
       "3683                           []                           []   \n",
       "3684                 [Zhang_Ziyi]                 [Zhang_Ziyi]   \n",
       "3685  [Circle_of_Friends_(novel)]  [Circle_of_Friends_(novel)]   \n",
       "3686                  [Barcelona]                  [Barcelona]   \n",
       "3687            [Gunnar_Johansen]            [Gunnar_Johansen]   \n",
       "\n",
       "                                  Spotlight  \n",
       "0                           [Roger_Marquis]  \n",
       "1                            [Carlos_Gómez]  \n",
       "2                       [Engelbert_Zaschka]  \n",
       "3                    [Pee_Wee_Reese, Urine]  \n",
       "4     [Switzerland, Conducting, Infarction]  \n",
       "...                                     ...  \n",
       "3683            [Abraham, Serbian_language]  \n",
       "3684                           [Zhang_Ziyi]  \n",
       "3685                               [Circle]  \n",
       "3686                            [Barcelona]  \n",
       "3687             [Gunnar_Johansen, Denmark]  \n",
       "\n",
       "[3688 rows x 9 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dbpedia_data('dsq',dsq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "VCkCwBeh8LSj",
   "metadata": {
    "id": "VCkCwBeh8LSj"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>empty</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>micro-precision</th>\n",
       "      <th>micro-recall</th>\n",
       "      <th>micro-f1</th>\n",
       "      <th>macro-precision</th>\n",
       "      <th>macro-recall</th>\n",
       "      <th>macro-f1</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3687</td>\n",
       "      <td>0</td>\n",
       "      <td>3506</td>\n",
       "      <td>0</td>\n",
       "      <td>25380</td>\n",
       "      <td>183</td>\n",
       "      <td>0.121374</td>\n",
       "      <td>0.950393</td>\n",
       "      <td>0.215257</td>\n",
       "      <td>0.210764</td>\n",
       "      <td>0.950380</td>\n",
       "      <td>0.296229</td>\n",
       "      <td>MuHeQA_Cand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3687</td>\n",
       "      <td>0</td>\n",
       "      <td>3367</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>321</td>\n",
       "      <td>0.944460</td>\n",
       "      <td>0.912961</td>\n",
       "      <td>0.928443</td>\n",
       "      <td>0.912012</td>\n",
       "      <td>0.912961</td>\n",
       "      <td>0.912328</td>\n",
       "      <td>MuHeQA_Rank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3687</td>\n",
       "      <td>0</td>\n",
       "      <td>3369</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>319</td>\n",
       "      <td>0.952233</td>\n",
       "      <td>0.913503</td>\n",
       "      <td>0.932466</td>\n",
       "      <td>0.913503</td>\n",
       "      <td>0.913503</td>\n",
       "      <td>0.913503</td>\n",
       "      <td>MuHeQA_Top1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3687</td>\n",
       "      <td>0</td>\n",
       "      <td>3351</td>\n",
       "      <td>0</td>\n",
       "      <td>467</td>\n",
       "      <td>337</td>\n",
       "      <td>0.877685</td>\n",
       "      <td>0.908623</td>\n",
       "      <td>0.892886</td>\n",
       "      <td>0.888964</td>\n",
       "      <td>0.908623</td>\n",
       "      <td>0.895517</td>\n",
       "      <td>MuHeQA_Top2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3687</td>\n",
       "      <td>0</td>\n",
       "      <td>3356</td>\n",
       "      <td>0</td>\n",
       "      <td>718</td>\n",
       "      <td>332</td>\n",
       "      <td>0.823760</td>\n",
       "      <td>0.909978</td>\n",
       "      <td>0.864726</td>\n",
       "      <td>0.864380</td>\n",
       "      <td>0.909978</td>\n",
       "      <td>0.879338</td>\n",
       "      <td>MuHeQA_Top3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3687</td>\n",
       "      <td>0</td>\n",
       "      <td>2345</td>\n",
       "      <td>0</td>\n",
       "      <td>1930</td>\n",
       "      <td>1344</td>\n",
       "      <td>0.548538</td>\n",
       "      <td>0.635674</td>\n",
       "      <td>0.588900</td>\n",
       "      <td>0.548717</td>\n",
       "      <td>0.635575</td>\n",
       "      <td>0.576762</td>\n",
       "      <td>Spotlight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total  empty    tp  tn     fp    fn  micro-precision  micro-recall  \\\n",
       "0   3687      0  3506   0  25380   183         0.121374      0.950393   \n",
       "1   3687      0  3367   0    198   321         0.944460      0.912961   \n",
       "2   3687      0  3369   0    169   319         0.952233      0.913503   \n",
       "3   3687      0  3351   0    467   337         0.877685      0.908623   \n",
       "4   3687      0  3356   0    718   332         0.823760      0.909978   \n",
       "5   3687      0  2345   0   1930  1344         0.548538      0.635674   \n",
       "\n",
       "   micro-f1  macro-precision  macro-recall  macro-f1        model  \n",
       "0  0.215257         0.210764      0.950380  0.296229  MuHeQA_Cand  \n",
       "1  0.928443         0.912012      0.912961  0.912328  MuHeQA_Rank  \n",
       "2  0.932466         0.913503      0.913503  0.913503  MuHeQA_Top1  \n",
       "3  0.892886         0.888964      0.908623  0.895517  MuHeQA_Top2  \n",
       "4  0.864726         0.864380      0.909978  0.879338  MuHeQA_Top3  \n",
       "5  0.588900         0.548717      0.635575  0.576762    Spotlight  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_report('dsq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2p24RwMo6Zet",
   "metadata": {
    "id": "2p24RwMo6Zet"
   },
   "source": [
    "## WikidataQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "yBPGSBrY6dbH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "yBPGSBrY6dbH",
    "outputId": "ccdcf9be-0e0e-421a-d409-b017b96d5e63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 questions analyzed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "      <th>resources</th>\n",
       "      <th>MuHeQA_Cand</th>\n",
       "      <th>MuHeQA_Rank</th>\n",
       "      <th>MuHeQA_Top1</th>\n",
       "      <th>MuHeQA_Top2</th>\n",
       "      <th>MuHeQA_Top3</th>\n",
       "      <th>WEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the president of Poland?</td>\n",
       "      <td>[president of Poland]</td>\n",
       "      <td>[Q1054799]</td>\n",
       "      <td>[Q1054799, Q7241287]</td>\n",
       "      <td>[Q1054799]</td>\n",
       "      <td>[Q1054799]</td>\n",
       "      <td>[Q1054799]</td>\n",
       "      <td>[Q1054799]</td>\n",
       "      <td>[Q1054799, Q36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many Turing awards have people from Austri...</td>\n",
       "      <td>[Turing awards,  Austria]</td>\n",
       "      <td>[Q185667,  Q40]</td>\n",
       "      <td>[Q185667, Q56067342, Q185667, Q40, Q131964, Q2...</td>\n",
       "      <td>[Q185667, Q185667, Q40]</td>\n",
       "      <td>[Q185667, Q40]</td>\n",
       "      <td>[Q185667, Q185667, Q40]</td>\n",
       "      <td>[Q185667, Q185667, Q40]</td>\n",
       "      <td>[Q185667, Q5, Q40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Give me all countries that have won a FIFA Wor...</td>\n",
       "      <td>[FIFA World Cup]</td>\n",
       "      <td>[Q19317]</td>\n",
       "      <td>[Q19317, Q864001, Q176883, Q170645, Q150933, Q...</td>\n",
       "      <td>[Q19317]</td>\n",
       "      <td>[Q19317]</td>\n",
       "      <td>[Q19317]</td>\n",
       "      <td>[Q19317]</td>\n",
       "      <td>[Q6256, Q19317]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the population of Chile?</td>\n",
       "      <td>[Chile]</td>\n",
       "      <td>[Q298]</td>\n",
       "      <td>[Q298, Q1045129, Q396324, Q18418541, Q5490088,...</td>\n",
       "      <td>[Q298]</td>\n",
       "      <td>[Q298]</td>\n",
       "      <td>[Q298]</td>\n",
       "      <td>[Q298]</td>\n",
       "      <td>[Q2625603, Q298]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is the author of One Piece?</td>\n",
       "      <td>[One Piece]</td>\n",
       "      <td>[Q673]</td>\n",
       "      <td>[Q200539, Q673, Q710324, Q28667972, Q4431905, ...</td>\n",
       "      <td>[Q28667972]</td>\n",
       "      <td>[Q673]</td>\n",
       "      <td>[Q673, Q710324]</td>\n",
       "      <td>[Q673, Q28667972, Q710324]</td>\n",
       "      <td>[Q482980, Q1048718, Q27953041]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Who wrote The Old Man and the Sea?</td>\n",
       "      <td>[The Old Man and the Sea]</td>\n",
       "      <td>[Q26505]</td>\n",
       "      <td>[Q26505, Q1198269, Q177145, Q387241, Q7754883,...</td>\n",
       "      <td>[Q26505]</td>\n",
       "      <td>[Q26505]</td>\n",
       "      <td>[Q26505]</td>\n",
       "      <td>[Q26505]</td>\n",
       "      <td>[Q1055469, Q498805]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Which YouTube channels talk about maths?</td>\n",
       "      <td>[YouTube channels,  maths]</td>\n",
       "      <td>[Q17558136,  Q395]</td>\n",
       "      <td>[Q108932203, Q108931581, Q17558136, Q63185508,...</td>\n",
       "      <td>[Q110991190, Q6786758]</td>\n",
       "      <td>[Q110991190, Q21148294]</td>\n",
       "      <td>[Q17558136, Q21148294]</td>\n",
       "      <td>[Q17558136, Q21148294]</td>\n",
       "      <td>[Q866, Q395]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>List Italian sauces.</td>\n",
       "      <td>[sauce,  Italy]</td>\n",
       "      <td>[Q178359,  Q38]</td>\n",
       "      <td>[Q178359, Q249114, Q1242466, Q429855, Q1015993...</td>\n",
       "      <td>[Q178359, Q38]</td>\n",
       "      <td>[Q178359, Q38]</td>\n",
       "      <td>[Q178359, Q38]</td>\n",
       "      <td>[Q178359, Q38]</td>\n",
       "      <td>[Q178359, Q52715628]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>What diseases are associated with the gene FGF14?</td>\n",
       "      <td>[FGF14]</td>\n",
       "      <td>[Q17928040]</td>\n",
       "      <td>[Q17928040, Q18250567, Q24785004, Q24396191, Q...</td>\n",
       "      <td>[Q17928040]</td>\n",
       "      <td>[Q17928040]</td>\n",
       "      <td>[Q17928040]</td>\n",
       "      <td>[Q17928040]</td>\n",
       "      <td>[Q12136, Q7187, Q17928040]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>What ultra-cool dwarfs have been found in the ...</td>\n",
       "      <td>[ultra-cool dwarfs,  Aquarius]</td>\n",
       "      <td>[Q24039974,  Q10576]</td>\n",
       "      <td>[Q68675654, Q24039974, Q68675654, Q68360378, Q...</td>\n",
       "      <td>[Q24039974, Q1210656]</td>\n",
       "      <td>[Q24039974, Q10576]</td>\n",
       "      <td>[Q24039974, Q68360378, Q10576]</td>\n",
       "      <td>[Q24039974, Q68360378, Q10576]</td>\n",
       "      <td>[Q214045, Q8928, Q162119]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                      Who is the president of Poland?   \n",
       "1    How many Turing awards have people from Austri...   \n",
       "2    Give me all countries that have won a FIFA Wor...   \n",
       "3                     What is the population of Chile?   \n",
       "4                      Who is the author of One Piece?   \n",
       "..                                                 ...   \n",
       "96                  Who wrote The Old Man and the Sea?   \n",
       "97            Which YouTube channels talk about maths?   \n",
       "98                                List Italian sauces.   \n",
       "99   What diseases are associated with the gene FGF14?   \n",
       "100  What ultra-cool dwarfs have been found in the ...   \n",
       "\n",
       "                           entities             resources  \\\n",
       "0             [president of Poland]            [Q1054799]   \n",
       "1         [Turing awards,  Austria]       [Q185667,  Q40]   \n",
       "2                  [FIFA World Cup]              [Q19317]   \n",
       "3                           [Chile]                [Q298]   \n",
       "4                       [One Piece]                [Q673]   \n",
       "..                              ...                   ...   \n",
       "96        [The Old Man and the Sea]              [Q26505]   \n",
       "97       [YouTube channels,  maths]    [Q17558136,  Q395]   \n",
       "98                  [sauce,  Italy]       [Q178359,  Q38]   \n",
       "99                          [FGF14]           [Q17928040]   \n",
       "100  [ultra-cool dwarfs,  Aquarius]  [Q24039974,  Q10576]   \n",
       "\n",
       "                                           MuHeQA_Cand  \\\n",
       "0                                 [Q1054799, Q7241287]   \n",
       "1    [Q185667, Q56067342, Q185667, Q40, Q131964, Q2...   \n",
       "2    [Q19317, Q864001, Q176883, Q170645, Q150933, Q...   \n",
       "3    [Q298, Q1045129, Q396324, Q18418541, Q5490088,...   \n",
       "4    [Q200539, Q673, Q710324, Q28667972, Q4431905, ...   \n",
       "..                                                 ...   \n",
       "96   [Q26505, Q1198269, Q177145, Q387241, Q7754883,...   \n",
       "97   [Q108932203, Q108931581, Q17558136, Q63185508,...   \n",
       "98   [Q178359, Q249114, Q1242466, Q429855, Q1015993...   \n",
       "99   [Q17928040, Q18250567, Q24785004, Q24396191, Q...   \n",
       "100  [Q68675654, Q24039974, Q68675654, Q68360378, Q...   \n",
       "\n",
       "                 MuHeQA_Rank              MuHeQA_Top1  \\\n",
       "0                 [Q1054799]               [Q1054799]   \n",
       "1    [Q185667, Q185667, Q40]           [Q185667, Q40]   \n",
       "2                   [Q19317]                 [Q19317]   \n",
       "3                     [Q298]                   [Q298]   \n",
       "4                [Q28667972]                   [Q673]   \n",
       "..                       ...                      ...   \n",
       "96                  [Q26505]                 [Q26505]   \n",
       "97    [Q110991190, Q6786758]  [Q110991190, Q21148294]   \n",
       "98            [Q178359, Q38]           [Q178359, Q38]   \n",
       "99               [Q17928040]              [Q17928040]   \n",
       "100    [Q24039974, Q1210656]      [Q24039974, Q10576]   \n",
       "\n",
       "                        MuHeQA_Top2                     MuHeQA_Top3  \\\n",
       "0                        [Q1054799]                      [Q1054799]   \n",
       "1           [Q185667, Q185667, Q40]         [Q185667, Q185667, Q40]   \n",
       "2                          [Q19317]                        [Q19317]   \n",
       "3                            [Q298]                          [Q298]   \n",
       "4                   [Q673, Q710324]      [Q673, Q28667972, Q710324]   \n",
       "..                              ...                             ...   \n",
       "96                         [Q26505]                        [Q26505]   \n",
       "97           [Q17558136, Q21148294]          [Q17558136, Q21148294]   \n",
       "98                   [Q178359, Q38]                  [Q178359, Q38]   \n",
       "99                      [Q17928040]                     [Q17928040]   \n",
       "100  [Q24039974, Q68360378, Q10576]  [Q24039974, Q68360378, Q10576]   \n",
       "\n",
       "                                WEL  \n",
       "0                   [Q1054799, Q36]  \n",
       "1                [Q185667, Q5, Q40]  \n",
       "2                   [Q6256, Q19317]  \n",
       "3                  [Q2625603, Q298]  \n",
       "4    [Q482980, Q1048718, Q27953041]  \n",
       "..                              ...  \n",
       "96              [Q1055469, Q498805]  \n",
       "97                     [Q866, Q395]  \n",
       "98             [Q178359, Q52715628]  \n",
       "99       [Q12136, Q7187, Q17928040]  \n",
       "100       [Q214045, Q8928, Q162119]  \n",
       "\n",
       "[101 rows x 9 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_wiki_data('wqa',wqa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "x7yNEoWt6f0T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "x7yNEoWt6f0T",
    "outputId": "6f7479ae-1581-486c-c953-17543d2bce20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>empty</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>micro-precision</th>\n",
       "      <th>micro-recall</th>\n",
       "      <th>micro-f1</th>\n",
       "      <th>macro-precision</th>\n",
       "      <th>macro-recall</th>\n",
       "      <th>macro-f1</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>1513</td>\n",
       "      <td>22</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.150526</td>\n",
       "      <td>0.122803</td>\n",
       "      <td>0.828383</td>\n",
       "      <td>0.188930</td>\n",
       "      <td>MuHeQA_Cand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>71</td>\n",
       "      <td>0.436842</td>\n",
       "      <td>0.538961</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>0.496445</td>\n",
       "      <td>0.520627</td>\n",
       "      <td>0.503386</td>\n",
       "      <td>MuHeQA_Rank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.575083</td>\n",
       "      <td>0.570132</td>\n",
       "      <td>0.571782</td>\n",
       "      <td>MuHeQA_Top1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>62</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.558251</td>\n",
       "      <td>0.585809</td>\n",
       "      <td>0.568725</td>\n",
       "      <td>MuHeQA_Top2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>59</td>\n",
       "      <td>0.467337</td>\n",
       "      <td>0.611842</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.518152</td>\n",
       "      <td>0.605611</td>\n",
       "      <td>0.549890</td>\n",
       "      <td>MuHeQA_Top3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>55</td>\n",
       "      <td>0.458937</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.532213</td>\n",
       "      <td>0.521452</td>\n",
       "      <td>0.636964</td>\n",
       "      <td>0.546582</td>\n",
       "      <td>WEL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total  empty   tp  tn    fp  fn  micro-precision  micro-recall  micro-f1  \\\n",
       "0    100      4  136   0  1513  22         0.082474      0.860759  0.150526   \n",
       "1    100      4   83   0   107  71         0.436842      0.538961  0.482558   \n",
       "2    100      4   84   0    62  66         0.575342      0.560000  0.567568   \n",
       "3    100      4   90   0    76  62         0.542169      0.592105  0.566038   \n",
       "4    100      4   93   0   106  59         0.467337      0.611842  0.529915   \n",
       "5    100      4   95   0   112  55         0.458937      0.633333  0.532213   \n",
       "\n",
       "   macro-precision  macro-recall  macro-f1        model  \n",
       "0         0.122803      0.828383  0.188930  MuHeQA_Cand  \n",
       "1         0.496445      0.520627  0.503386  MuHeQA_Rank  \n",
       "2         0.575083      0.570132  0.571782  MuHeQA_Top1  \n",
       "3         0.558251      0.585809  0.568725  MuHeQA_Top2  \n",
       "4         0.518152      0.605611  0.549890  MuHeQA_Top3  \n",
       "5         0.521452      0.636964  0.546582          WEL  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_report('wqa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a65a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "ee8r4_O_VKUq",
    "HNrfwq21VLpu",
    "vYys9IuHaTXO",
    "Np4sKzSbaVaG",
    "u0HBoh39X-Xs",
    "qbby_0brtpot"
   ],
   "name": "MuHeQA-Entity_Linking.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".eqakg",
   "language": "python",
   "name": ".eqakg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
